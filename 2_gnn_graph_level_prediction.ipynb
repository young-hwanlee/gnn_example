{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOha6YYTldZNvTt72hvyfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hwanlee/gnn_examples/blob/main/2_gnn_graph_level_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6Dj6lSNdk2o4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d742d70-85db-45ac-c742-5174c44536ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gnn_examples' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/young-hwanlee/gnn_examples.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## To avoid some errors (출처: https://life-is-potatoo.tistory.com/95 [삶은 감자:티스토리]) ==========\n",
        "# ## 1st method\n",
        "# import torch\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# def format_pytorch_version(version):\n",
        "#     return version.split('+')[0]\n",
        "\n",
        "# TORCH_version = torch.__version__\n",
        "# TORCH = format_pytorch_version(TORCH_version)\n",
        "# def format_cuda_version(version):\n",
        "#     return 'cu' + version.replace('.', '')\n",
        "\n",
        "# CUDA_version = torch.version.cuda\n",
        "# CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "## Ensure that the PyTorch and the PyG are the same version\n",
        "# !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-geometric\n",
        "\n",
        "## 2nd method\n",
        "import os\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "# !pip install torch_geometric\n",
        "\n",
        "## Ensure that the PyTorch and the PyG are the same version\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install pytorch_metric_learning\n",
        "\n",
        "## Both methods are too slow."
      ],
      "metadata": {
        "id": "1hIIvUhSlH_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b42ac5f-fbe3-4a01-9716-bfee9951d2e0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytorch_metric_learning in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.3.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.6.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch_metric_learning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import required packages ====================================================================\n",
        "# import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.nn.pool import global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FyikFVMblJSG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set up the seed for reproducibility ============================================================\n",
        "seed = 42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)     # if use multi-GPU\n",
        "\n",
        "np.random.seed(seed)\n",
        "\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "kOnmlcZjzbrK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load a dataset ===============================================================================\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "dataset = TUDataset(root=\"/tmp/PROTEINS\", name=\"PROTEINS\", transform=torch_geometric.transforms.ToDevice(device))"
      ],
      "metadata": {
        "id": "kINoZ6oolJOp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dataset: {dataset}:')\n",
        "print('============================================================================================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of labels: {len(dataset.y)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print(f'Classes: {torch.unique(dataset.y)}')\n",
        "print(f'Number of y = 0: {len(np.array(torch.where(dataset.y == 0)).flatten())}')\n",
        "print(f'Number of y = 1: {len(np.array(torch.where(dataset.y == 1)).flatten())}')\n",
        "print('============================================================================================')\n",
        "for i in range(0, len(dataset)):\n",
        "    if i % 100 == 0:\n",
        "        print(f'{i} : {dataset[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vxz1v9CQdRj",
        "outputId": "60320fb0-bec2-47c6-ed66-bfba00a73451"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: PROTEINS(1113):\n",
            "============================================================================================\n",
            "Number of graphs: 1113\n",
            "Number of labels: 1113\n",
            "Number of features: 3\n",
            "Number of classes: 2\n",
            "Classes: tensor([0, 1])\n",
            "Number of y = 0: 663\n",
            "Number of y = 1: 450\n",
            "============================================================================================\n",
            "0 : Data(edge_index=[2, 162], x=[42, 3], y=[1])\n",
            "100 : Data(edge_index=[2, 214], x=[50, 3], y=[1])\n",
            "200 : Data(edge_index=[2, 216], x=[52, 3], y=[1])\n",
            "300 : Data(edge_index=[2, 332], x=[96, 3], y=[1])\n",
            "400 : Data(edge_index=[2, 114], x=[33, 3], y=[1])\n",
            "500 : Data(edge_index=[2, 150], x=[43, 3], y=[1])\n",
            "600 : Data(edge_index=[2, 180], x=[46, 3], y=[1])\n",
            "700 : Data(edge_index=[2, 12], x=[4, 3], y=[1])\n",
            "800 : Data(edge_index=[2, 188], x=[45, 3], y=[1])\n",
            "900 : Data(edge_index=[2, 46], x=[11, 3], y=[1])\n",
            "1000 : Data(edge_index=[2, 18], x=[5, 3], y=[1])\n",
            "1100 : Data(edge_index=[2, 128], x=[36, 3], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31GXI3hz1Uk",
        "outputId": "429119f4-8b48-4ea8-d689-414a9569c014"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1113"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[700].x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yTJ3YFZ8eZ1",
        "outputId": "64ad9c0a-d8e8-430f-b178-da1150511085"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx_tmp, test_idx = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "aEmIDbVHyMvO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(train_idx_tmp).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQydZFVY7MT-",
        "outputId": "965f9cec-ed7d-422b-ada5-4510675ac58a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 381,  327,  997,  958,  582,  783,  737,  845,  296,  298,    2,\n",
              "          6, 1036,  346, 1001,  247,  351,  767,  896,  215,  436,  539,\n",
              "        485,  270,  448,  265, 1085,  930,  380,  332,  622,  643,  787,\n",
              "        907,  618,  256,   25,  321,   47,  106,   55, 1077,  213,  120,\n",
              "        451,  847,   72,  634,  359,  306,  409,  439,  596,  336,  941,\n",
              "        786,  529,  704,  394,  584,  846,  430,   60,  551,   92, 1062,\n",
              "        290, 1000,  280,  309,  945,  404,  182,  549,  319,  110,  411,\n",
              "        668,  538,  493,  355,  365,  261,  352,  602,  712,  885,  137,\n",
              "        601,  675,  909,  478,  673, 1081,   29,  165,  248,  307,  398,\n",
              "        947,  342,  881,  851,  789,  593,  992,  588,   65,  458,  998,\n",
              "        636,  254,  812,  312,  490,  221,  235,  688,  894,  305,  367,\n",
              "        677, 1057,  249,  644,  590,   71,   94,  429,   33,  730,  259,\n",
              "        204,  467, 1060,  445,   77,   84,  890,   82, 1084,  745,  732,\n",
              "        731,  620,  435,  541,  350,  990,    5,  310,  554,  104,   97,\n",
              "        630,  777,  314,  519,  617,   62,  281,  631,  266,  566,  238,\n",
              "       1026,  145, 1039,  442,  628,  118,  682, 1038,  250,  933,  285,\n",
              "       1020,    9,  465,  196,  740,  370,   81,  389,  534,  595,  758,\n",
              "        568,  239,  629,  211,  872,  144,  938,  581,  227, 1029,  626,\n",
              "        494,  961,  177, 1075, 1047,  135,  594,  457,  481, 1109,    7,\n",
              "       1067,  155,  716,  357,  650,  223,  329,  599,  548, 1010,  462,\n",
              "        689,  757,  983,  756,  915, 1074,  692,  918,  728, 1059,  440,\n",
              "        711, 1112,  813,  163,  228,  994,  886,  212,  928,   79,  148,\n",
              "        302, 1093,  788,  790,  497,   43,  589,  133,  701,  523,  605,\n",
              "        311,  408,  575,  743,  968,  953,  993,  913,    0,  422,  360,\n",
              "        382,  316,  939,  475,  859,  660,  532,  661, 1073,  140,  172,\n",
              "        450,  125,  801,  567,  666, 1056,   90, 1078,  181,  363, 1071,\n",
              "        274,  848,  251,   69,  131,  300,  572,  326,  861,  499,  694,\n",
              "        781,  495,  338,  816,  164,   28,  516,  193,  893,  169,  604,\n",
              "        173,  518,  782,  597,  491,   73,  832,  234,  214, 1101,  132,\n",
              "        621,  799,  185,   41,  108,  720,  966,  849,  483,  468,   24,\n",
              "        901, 1037,  792,  843,  366,  714,  383,  454,  264,  963, 1091,\n",
              "        444,  395,  176,   18,  707,  693,   61,  272, 1045,  278,  715,\n",
              "        368,  753,  908,  657,  547,  746,  882,  456,  393,  774,  817,\n",
              "        375,  412,   74, 1041,  500,  803,  114,  417,   89, 1065,  498,\n",
              "        989,  785,   11,  396,  905,  959,   42,  167,  416,  576,  917,\n",
              "        426,  544, 1042, 1092,  833,  750,  257,  335,   15, 1007,  324,\n",
              "        926,  919,  222,  179,   99,  521,   22,  356,  814, 1033,  611,\n",
              "        902,  340,  431,  665, 1005,  203,  866,   93,  678,   68,  761,\n",
              "        284,  970,  434,  153,   75,  889,  580,  446,  188,  271,  236,\n",
              "        487, 1076,  559,  117, 1070, 1015,  512,  633,  667,  852,  723,\n",
              "        126,  116,  473,  842,   57,  603,  822,  656, 1103,  784,  105,\n",
              "        635,  369,  268,  655,   46,  349,  195,  102, 1006, 1013, 1079,\n",
              "        895,  263,  911,  443,  823,  718,  923,  304,  341,  736,  313,\n",
              "        149,  124,  950,  991,  697,  664,   50,  353, 1069,  142,  470,\n",
              "        653,  399,  764,  320,   19,  684,  976,  954, 1088,  407,  537,\n",
              "        967,  759,   38,  175,  245,  999,  828,  914,  489,  154,  638,\n",
              "        662,  287,  625,  685,  739,  569,  903,  734,   17,  127,  322,\n",
              "        255,  802, 1111,  190,  115, 1089,  755,  606,  180,  301,  920,\n",
              "        867,  880,  834,  943,  809,  517,  372,   45,  476,  157,  904,\n",
              "        171,   16,  511,   48,  191, 1014,  515,  921,  888,  480,  283,\n",
              "        873,  798,  225,   26,  946, 1066,  437, 1083,  364,  229,   37,\n",
              "        669,  749, 1096,  374,  469, 1097,  687,   32,  855,  883,  194,\n",
              "       1028, 1035,  503, 1098, 1002,  800,  579,  160,  680, 1049,  162,\n",
              "        705,  853,  152,  830,  850,  916,  111,  226,  837,  103,  421,\n",
              "        419,  910,  586,  944,  672,  119,   53,  151,  403, 1104,  207,\n",
              "       1053,  658, 1019,  924,    8,  974,   36,  452,  651,  253,  303,\n",
              "        906,  571,  623,  862,  874,  864,  262,  610,  297,  414,  150,\n",
              "        964,  778,  640, 1048,  550, 1068,  488,  819,  710,  147,  146,\n",
              "        876,  345,  898, 1110,  659,  770,  348,  463,  325,  186,  123,\n",
              "       1027,  608,  143,  751, 1090,  197,  609,  836,  279,  293, 1003,\n",
              "        400,  122,  183,  202,  438,  835,  246,  415,  940,  927, 1058,\n",
              "        931,   52,  129,  637,  402,  948,  934,  735,  854, 1061,  219,\n",
              "        641,    1,  912,  972,   80,  624, 1011,  922,  386, 1100,  806,\n",
              "        509,  267,  987,  441,  496,  829,  112,  691,  232,  471,  607,\n",
              "        671,  373,  826,  663, 1018,  233,  818,  949,  676,  317,  648,\n",
              "        410, 1052,  709,  358,  258,  744,  627,  632,  282,  376,  384,\n",
              "        224, 1087,  981,  472,  347,  505,  639, 1107,  797,  339,  555,\n",
              "        619,   27,  969,  645,  952, 1022,  556,  681,  577,  795,   85,\n",
              "        242,  698,  838,  159,  524,   35,  540,  170,  654,  748, 1031,\n",
              "       1023,  484,  733,  899,   95,  563,  240,  742,  863,  574,  690,\n",
              "        460,  891,  553,  857, 1040,  206,  392,  794,  870,  397,  766,\n",
              "       1024,  217,    4,  768,  642,  461,  942,  612,  738,  960,  546,\n",
              "        986,  725, 1105,  683,   98,  804,  727,  573,  406,  502,  929,\n",
              "        779,  200,  134,   40, 1017,  230,  378,  288,  418,  391,  592,\n",
              "        647,  520,   64,   14,  492,  379,  187,  763,  216,  791,  878,\n",
              "        337,  719,  295, 1016,  455,  815,  269,  995,  201,  161,  729,\n",
              "        401,  702,  565, 1021, 1025,  205,   34,  775,  508, 1099,   91,\n",
              "        897,  564,  776,  241,   13,  315,  600,  387,  166,  840,   20,\n",
              "        646,  831,  562, 1086,  686,  957,  189,  975,  699,  510, 1082,\n",
              "        474,  856,  747,  252,   21,  459,  276,  955,  385,  805,  343,\n",
              "        769,  130,  871,   87,  330,  466,  121, 1044, 1095,  860])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_idx_tmp = train_idx_tmp[:2]\n",
        "print(dataset_idx_tmp)\n",
        "\n",
        "data_tmp = dataset[dataset_idx_tmp]\n",
        "\n",
        "print(data_tmp[0])\n",
        "print(data_tmp[1])\n",
        "\n",
        "try:\n",
        "    print(data_tmp[2])\n",
        "except IndexError:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPmou-dPhMMX",
        "outputId": "9a062949-9567-4f9b-fe38-ed90e88ac5f8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[381, 327]\n",
            "Data(edge_index=[2, 276], x=[69, 3], y=[1])\n",
            "Data(edge_index=[2, 250], x=[62, 3], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tmp = dataset[:2]\n",
        "\n",
        "print(data_tmp[0])\n",
        "print(data_tmp[1])\n",
        "\n",
        "try:\n",
        "    print(data_tmp[2])\n",
        "except IndexError:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmROl8INhZT2",
        "outputId": "c807bef3-d0cd-4046-ecbc-b2c658991c29"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 162], x=[42, 3], y=[1])\n",
            "Data(edge_index=[2, 92], x=[27, 3], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_tmp = dataset[train_idx_tmp]\n",
        "train_idx, val_idx = train_test_split(list(range(len(train_dataset_tmp))), test_size=0.25, random_state=seed)\n",
        "\n",
        "train_dataset = train_dataset_tmp[train_idx]\n",
        "val_dataset = train_dataset_tmp[val_idx]\n",
        "test_dataset = dataset[test_idx]\n",
        "\n",
        "print(f'Number of train data: {len(train_dataset)}')\n",
        "print(f'Number of val data: {len(val_dataset)}')\n",
        "print(f'Number of test data: {len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhvDSYB-laUK",
        "outputId": "e0556181-b6e0-4042-f443-4c8d4f2264df"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train data: 667\n",
            "Number of val data: 223\n",
            "Number of test data: 223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mini-batch loaderl =======================================================================\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "for graph in train_loader:\n",
        "    print(graph)\n",
        "    break\n",
        "print(train_loader)\n",
        "print(train_loader.dataset)"
      ],
      "metadata": {
        "id": "EnNa12jCJZ6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3761f6ca-34d0-482f-c046-1cadd1d4a9fe"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataBatch(edge_index=[2, 12762], x=[3352, 3], y=[64], batch=[3352], ptr=[65])\n",
            "<torch_geometric.loader.dataloader.DataLoader object at 0x7aba7f4b1b40>\n",
            "PROTEINS(667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your GNN model ===========================================================================\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(seed)\n",
        "        # Choose between different GNN building blocks:\n",
        "        self.conv1 = GATConv(dataset.num_features, 16)\n",
        "        self.conv2 = GATConv(16, 16)\n",
        "        self.lin = torch.nn.Linear(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        return self.lin(x)\n",
        "\n",
        "num_classes = dataset.y.max().item() + 1       # Assuming classes are indexed from 0\n",
        "# model = GNN()\n",
        "model = GNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "-fP7KFBklJFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035edeb4-ef7b-4e2c-9677-f590be122fcf"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN(\n",
            "  (conv1): GATConv(3, 16, heads=1)\n",
            "  (conv2): GATConv(16, 16, heads=1)\n",
            "  (lin): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test your GNN model =======================================================================\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def test(model, data_loader):\n",
        "    loss, correct = 0, 0\n",
        "\n",
        "    model.eval()\n",
        "    for data in data_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        loss += criterion(out, data.y).item() / len(data_loader)\n",
        "        correct += torch.sum(out.argmax(dim=1) == data.y)\n",
        "\n",
        "    acc = correct / len(data_loader.dataset)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    pred = model(test_dataset.x, test_dataset.edge_index).argmax(dim=1)\n",
        "    correct = pred == test_dataset.y\n",
        "    acc = int(correct.sum()) / int(test_dataset.test_mask.sum())\n",
        "\n",
        "    return acc\n",
        "\n",
        "def train(model, train_loader, n_epochs):\n",
        "    model = model.to(device=device)\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = 0, 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "\n",
        "            optimizer.zero_grad()       # Clear gradients\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y)     # Compute the loss solely based on the training nodes\n",
        "            train_loss += loss.item() / len(train_loader.dataset)\n",
        "            train_acc += torch.sum(out.argmax(dim=1) == data.y) / len(train_loader.dataset)\n",
        "            loss.backward()     # Derive gradients\n",
        "            optimizer.step()     # Update parameters based on gradients\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            val_loss, val_acc = test(model, val_loader)\n",
        "            print(f'Epoch : {epoch:03d}, | Train loss : {train_loss:.4f}, | Train accuracy : {train_acc:.4f} | Valid loss : {val_loss:.4f}, | Valid accuracy : {val_acc:.4f}')\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = model\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "TCy6w-xNf9DM"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = train(model, train_loader, n_epochs=200)\n",
        "\n",
        "print('\\n')\n",
        "test_loss, test_acc = test(best_model, data_loader=test_loader)\n",
        "print(f'Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "0peq3orslJAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "ed32ea41-1c6f-479d-fd31-86625f7b009e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GNN.forward() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-ed3b9ace2cd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {test_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-63b9cf643ca0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, n_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch : {epoch:03d}, | Train loss : {train_loss:.4f}, | Train accuracy : {train_acc:.4f} | Valid loss : {val_loss:.4f}, | Valid accuracy : {val_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-63b9cf643ca0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GNN.forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdTBoazslJLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cV5zSkFslJIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0lPpnm3lIux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}